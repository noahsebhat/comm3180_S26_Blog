[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Noah",
    "section": "",
    "text": "Hello! My name is Noah, and I’m a senior at Penn studying Philosophy, Politics & Economics with a minor in Data Science. This blog is intended to document my analysis of and reactions to different data sets and the exciting stories that they reveal. Thank you for joining me on this journey!"
  },
  {
    "objectID": "posts/DOW2_personality/DOW2.html",
    "href": "posts/DOW2_personality/DOW2.html",
    "title": "Noah's Blog",
    "section": "",
    "text": "---\ntitle: \"The Most Average American\"\nauthor: Noah Sebhatleab\ndate: 02/20/26\ncategories:\n  - DOW\n  - Personality\n---\n\n\nPolitical speeches, marketing reports, and news headlines often refer to an “average American”. But in a country as large and diverse as the United States, it’s not immediately obvious who that person is and what they’re actually like. Using publicly available personality survey data, I tried to figure it out and piece together an identity for this freqently mentioned but rarely defined figure.\nFirst, I wanted to understand the demographics of the average American: their age, race, and gender. According to the data, the average American is a 21 year old White woman.\nSet up\n\nimport pandas as pd\nimport re\n\nLoading the data\n\nbig5 = pd.read_csv('data/openpsych_data_scored.csv')\n\nSubsetting for just US (people who completed the survey in the US)\n\nbig5_us = big5[big5[\"country\"] == \"US\"]\n\nAge\n\nmed_age = big5_us[\"age\"].median()\nprint(med_age)\n\n21.0\n\n\nRace\n\nmode_race = big5_us[\"race\"].mode()\nprint(mode_race)\n\n0    3\nName: race, dtype: int64\n\n\n\nrace_values = '''1=Mixed Race, 2=Arctic (Siberian, Eskimo), 3=Caucasian (European), \n4=Caucasian (Indian), 5=Caucasian (Middle East), 6=Caucasian (North African, Other), \n7=Indigenous Australian, 8=Native American, \n9=North East Asian (Mongol, Tibetan, Korean Japanese, etc), \n10=Pacific (Polynesian, Micronesian, etc), \n11=South East Asian (Chinese, Thai, Malay, Filipino, etc), 12=West African, Bushmen, Ethiopian, 13=Other, 0=missed\n'''\n\nparts = re.split(r'(?:,\\s+)?([0-9]+)=', race_values.strip())\n\nrace_keys = [int(key_val) for key_val in parts[1::2]]\nrace_values = parts[2::2] #Pasted from class workbook\n\n\nrace_mapping = dict(zip(race_keys,race_values))\n\nGender\n\nmode_gender = big5_us[\"gender\"].mode()\nprint(mode_gender)\n\n0    2\nName: gender, dtype: int64\n\n\nBut what is this person like? The personality survey scores respondents across five traits: openness, conscientiousness, extroversion, agreeableness, and neuroticism, giving them a percentile score for each. Calculating the median of each trait, I found that the average American falls into the 52nd percentile for openness, 52nd for conscientiousness, 49th for extroversion, 54th for agreeableness, 52nd for conscientiousness, and 54th for neuroticism.\nCalculating median across each trait and plotting\n\ntraits = ['E_pct', 'A_pct', 'C_pct', 'N_pct', 'O_pct']\n\nmed_personality = big5_us[traits].median().round(1)\n\n\ntrait_labels = {\n    'E_pct': 'Extraversion',\n    'A_pct': 'Agreeableness',\n    'C_pct': 'Conscientiousness',\n    'N_pct': 'Neuroticism',\n    'O_pct': 'Openness'\n}\n\nmed_personality = med_personality.rename(index = trait_labels)\n\n\nimport matplotlib.pyplot as plt\n\n\nmed_personality.plot(kind = 'bar')\n\nplt.title(\"Median American Personality Profile\")\nplt.xlabel(\"Personality Trait\")\nplt.ylabel(\"Percentile\")\n\nplt.show()\n\n\n\n\n\n\n\n\nWhile these results help shed light on the identity of the average American, they may be more of an abstraction rather than an accurate representation. They certaintly don’t represent me or many of the Americans that I know. To understand how representative this profile really is, I measured how far each person’s personality differs from the median across the five traits. On average, respondents differ from the median profile by 25.4 percentile points per trait!\nDeviation\n\nbig5_us_clean = big5_us.dropna(subset = traits) #This command suddenly started returning 'nan'\n#so I used ChatGPT to add a line to drop the NAs\n\nmed_personality = big5_us_clean[traits].median()\n\ndiff = abs(big5_us[traits] - med_personality)\n\nbig5_us['deviation'] = diff.mean(axis = 1)\n\nmedian_dev = big5_us['deviation'].median()\n\nprint(median_dev) #Also used ChatGPT to think through how I could structure the deviation commands\n\n25.4\n\n\nIn other words, the average American isn’t very average at all. Part of the reason may be that personality shifts over time, meaning there isn’t one typical profile for all ages. To test this, I calculated average personality profiles across different age groups: under 18, 18-24, 25-34, 35-49, and 50+.\nPersonality by age\n\nbins = [0, 18, 25, 35, 50, 100]\nlabels = ['Under 18', '18–24', '25–34', '35–49', '50+']\n\nbig5_us['age group'] = pd.cut(\n    big5_us['age'],\n    bins=bins,\n    labels=labels,\n    right=False\n) #Used ChatGPT to see how I could group by age and make the table\n\n\ntraits = ['E_pct', 'A_pct', 'C_pct', 'N_pct', 'O_pct']\n\nage_profiles = big5_us.groupby('age group')[traits].median()\n\nage_profiles = big5_us.groupby('age group')[traits].median()\n\nage_profiles.columns = ['Extraversion',\n                        'Agreeableness',\n                        'Conscientiousness',\n                        'Neuroticism',\n                        'Openness']\n\nage_profiles\n\n\n\n\n\n\n\n\nExtraversion\nAgreeableness\nConscientiousness\nNeuroticism\nOpenness\n\n\nage group\n\n\n\n\n\n\n\n\n\nUnder 18\n49.0\n42.0\n37.0\n44.0\n52.0\n\n\n18–24\n49.0\n54.0\n52.0\n50.0\n52.0\n\n\n25–34\n53.0\n59.0\n57.0\n54.0\n58.0\n\n\n35–49\n53.0\n59.0\n67.0\n62.0\n52.0\n\n\n50+\n57.0\n65.0\n67.0\n66.0\n58.0\n\n\n\n\n\n\n\nUnsurprisingly, personality varies noticeably across age groups, with older groups scoring higher across almost every trait. The biggest changes appear in conscientiousness and agreeableness, which rise sharply with age, suggesting that Americans tend to become more responsible and socially cooperative over time.\nIn the end, the average American turns out to be more of a statistical idea than a true representation. While some people come close or even perfectly match the profile, most differ from it significantly, and what counts as “average” changes with age. In a country as diverse as the US, no single identity can capture the whole picture. And that’s okay!"
  },
  {
    "objectID": "posts/01_test_post/Noah_test_blog.html",
    "href": "posts/01_test_post/Noah_test_blog.html",
    "title": "Noah’s Test Blog",
    "section": "",
    "text": "Testing"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Noah’s Blog",
    "section": "",
    "text": "DOW2 Analysis Notebook\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s the Best Day (for me) to Get Married in Philadelphia?\n\n\n\nDOW\n\nWeather\n\n\n\n\n\n\n\n\n\nFeb 6, 2026\n\n\nNoah Sebhatleab\n\n\n\n\n\n\n\n\n\n\n\n\nNoah’s Test Blog\n\n\n\nTesting Blog\n\n\n\nTesting Blogging\n\n\n\n\n\nJan 24, 2026\n\n\nNoah\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nvisualization\n\ndata stories\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nJan 12, 2026\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "import matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/000_test_post/index.html#stories-from-data",
    "href": "posts/000_test_post/index.html#stories-from-data",
    "title": "A test post",
    "section": "Stories from data",
    "text": "Stories from data\n\nLet’s set up some data\n\n\nx = ['A', 'B', 'C']\ny = [1, 5, 3]\n\n\nNow let’s visualize it\n\nplt.bar(x, y)\nplt.show()"
  },
  {
    "objectID": "posts/DOW1_weather/DOW1.html",
    "href": "posts/DOW1_weather/DOW1.html",
    "title": "What’s the Best Day (for me) to Get Married in Philadelphia?",
    "section": "",
    "text": "I’m not getting married any time soon (at least I don’t think I am), but I sometimes think about what my ideal wedding would be like. An important component of that vision is the wedding date. There’s a lot of factors that dictate a good wedding date, like venue and guest availability, but perhaps the most important is weather. Using publicly available Philadelphia weather data, I looked to determine which single date would be the best for me to get married in Philadelphia, given my weather and wedding type preferences.\nI’ve always thought an outdoor wedding would be cool, so it’s important that it does not rain on the day of my wedding. Thus, my first step in determining my ideal wedding day was finding which has been the dryest day in the last 20 years.\nSet up\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nLoading the data\n\nweather_df = pd.read_csv('data/philadelphia_weather_2005_to_2025.csv')\nweather_df = weather_df.assign(date=pd.to_datetime(weather_df['date']))\n\nSubsetting days in the data that have had no recorded rain\n\nno_rain = weather_df[weather_df[\"rain\"] == 0]\n\nIdentifying commonly ocurring day in the subset\n\ndryest_day = no_rain[\"day\"].value_counts().idxmax()\nprint(dryest_day)\n\nAugust 26\n\n\nCounting the amount of times it has not rained on that day\n\ndryest_day_df = no_rain[no_rain[\"day\"] == dryest_day]\ncount = len(dryest_day_df)\nprint(count)\n\n21\n\n\nSince 2005, August 26th has been the dryest day, not recording a single day of rain. That’s great! But as a San Francisco native, I’ve grown up around moderate weather and don’t like it when it’s too hot or cold. So next, I wanted to find what the average temperature on August 26th has been over the last 20 years.\nCaluclating average temperature on August 26th\n\navg_temp = (dryest_day_df[\"high\"] + dryest_day_df[\"low\"]).mean() / 2\navg_temp = round(avg_temp, 1)\nprint(avg_temp)\n\n77.0\n\n\nThe average temperature on August 26th has been 77 degrees farenheight. That’s literally perfect. However, out of caution, I was interested in further examining the temperature data to make sure that the average temperature on August 26th hasn’t been trending too far up or down.\nPlotting the data\n\ndryest_day_df[\"avg_temp\"] = (dryest_day_df[\"high\"] + dryest_day_df[\"low\"]) / 2\nplt.scatter(dryest_day_df[\"year\"], dryest_day_df[\"avg_temp\"])\nplt.xlabel(\"Year\")\nplt.ylabel(\"Average Temperature\")\nplt.title(\"Average Temperature on August 26th (2005 - 2025)\")\nplt.show()\n\n\n\n\n\n\n\n\nLooking at the data, there doesn’t appear to a meaningful trend one way or the other so August 26th still checks out!\nOf course, no date comes with a weather guarantee, but if historical data is any guide, August 26th has some of the best odds for dry, warm weather in Philadelphia. So save the date! If and when I get married in Philadelphia, it will be on August 26th."
  },
  {
    "objectID": "posts/DOW2_personality/DOW2 Analysis Notebook.html",
    "href": "posts/DOW2_personality/DOW2 Analysis Notebook.html",
    "title": "DOW2 Analysis Notebook",
    "section": "",
    "text": "Set up\n\nimport pandas as pd\nimport re\n\n\nbig5 = pd.read_csv('data/openpsych_data_scored.csv')\n\n\nbig5.columns\n\nIndex(['race', 'age', 'engnat', 'gender', 'hand', 'source', 'country', 'E1',\n       'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'N1', 'N2', 'N3',\n       'N4', 'N5', 'N6', 'N7', 'N8', 'N9', 'N10', 'A1', 'A2', 'A3', 'A4', 'A5',\n       'A6', 'A7', 'A8', 'A9', 'A10', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7',\n       'C8', 'C9', 'C10', 'O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9',\n       'O10', 'race_cat', 'gender_cat', 'O', 'C', 'E', 'A', 'N', 'E_pct',\n       'A_pct', 'C_pct', 'N_pct', 'O_pct'],\n      dtype='str')\n\n\nAverage American (Demographics)\nFilter for Americans (completed survey in US)\n\nbig5_us = big5[big5[\"country\"] == \"US\"]\n\n\nlen(big5_us)\n\n8753\n\n\nAge\n\nmed_age = big5_us[\"age\"].median()\nprint(med_age)\n\n21.0\n\n\nRace\n\nmode_race = big5_us[\"race\"].mode()\nprint(mode_race)\n\n0    3\nName: race, dtype: int64\n\n\n\nrace_values = '''1=Mixed Race, 2=Arctic (Siberian, Eskimo), 3=Caucasian (European), \n4=Caucasian (Indian), 5=Caucasian (Middle East), 6=Caucasian (North African, Other), \n7=Indigenous Australian, 8=Native American, \n9=North East Asian (Mongol, Tibetan, Korean Japanese, etc), \n10=Pacific (Polynesian, Micronesian, etc), \n11=South East Asian (Chinese, Thai, Malay, Filipino, etc), 12=West African, Bushmen, Ethiopian, 13=Other, 0=missed\n'''\n\nparts = re.split(r'(?:,\\s+)?([0-9]+)=', race_values.strip())\n\nrace_keys = [int(key_val) for key_val in parts[1::2]]\nrace_values = parts[2::2] #Pasted from class workbook\n\n\nrace_mapping = dict(zip(race_keys,race_values))\nrace_mapping #Pasted from class workbook\n\n{1: 'Mixed Race',\n 2: 'Arctic (Siberian, Eskimo)',\n 3: 'Caucasian (European)',\n 4: 'Caucasian (Indian)',\n 5: 'Caucasian (Middle East)',\n 6: 'Caucasian (North African, Other)',\n 7: 'Indigenous Australian',\n 8: 'Native American',\n 9: 'North East Asian (Mongol, Tibetan, Korean Japanese, etc)',\n 10: 'Pacific (Polynesian, Micronesian, etc)',\n 11: 'South East Asian (Chinese, Thai, Malay, Filipino, etc)',\n 12: 'West African, Bushmen, Ethiopian',\n 13: 'Other',\n 0: 'missed'}\n\n\nEuropean caucasian\nGender\n\nmode_gender = big5_us[\"gender\"].mode()\nprint(mode_gender)\n\n0    2\nName: gender, dtype: int64\n\n\nFemale\n\nThe average American, according to the sample, is a 21 year old white female.\nPeronality\n\ntraits = ['E_pct', 'A_pct', 'C_pct', 'N_pct', 'O_pct']\n\nmed_personality = big5_us[traits].median().round(1)\nmed_personality\n\nE_pct    49.0\nA_pct    54.0\nC_pct    52.0\nN_pct    54.0\nO_pct    52.0\ndtype: float64\n\n\n\ntrait_labels = {\n    'E_pct': 'Extraversion',\n    'A_pct': 'Agreeableness',\n    'C_pct': 'Conscientiousness',\n    'N_pct': 'Neuroticism',\n    'O_pct': 'Openness'\n}\n\n\nmed_personality = med_personality.rename(index = trait_labels)\nmed_personality\n\nExtraversion         49.0\nAgreeableness        54.0\nConscientiousness    52.0\nNeuroticism          54.0\nOpenness             52.0\ndtype: float64\n\n\n\nimport matplotlib.pyplot as plt\n\n\nmed_personality.plot(kind = 'bar')\n\nplt.title(\"Median American Personality Profile\")\nplt.xlabel(\"Personality Trait\")\nplt.ylabel(\"Percentile\")\n\nplt.show()\n\n\n\n\n\n\n\n\nDeviation of respondents\n\nbig5_us_clean = big5_us.dropna(subset = traits) #This command suddenly started returning 'nan'\n#so I used ChatGPT to add a line to drop the NAs\n\nmed_personality = big5_us_clean[traits].median()\n\ndiff = abs(big5_us[traits] - med_personality)\n\nbig5_us['deviation'] = diff.mean(axis = 1)\n\nmedian_dev = big5_us['deviation'].median()\n\nprint(median_dev) #Also used ChatGPT to think through how I could structure the deviation commands\n\n25.4\n\n\nPerson by age\n\nbins = [0, 18, 25, 35, 50, 100]\nlabels = ['Under 18', '18–24', '25–34', '35–49', '50+']\n\nbig5_us['age group'] = pd.cut(\n    big5_us['age'],\n    bins=bins,\n    labels=labels,\n    right=False\n) #Used ChatGPT to see how I could group by age and make the table\n\n\ntraits = ['E_pct', 'A_pct', 'C_pct', 'N_pct', 'O_pct']\n\nage_profiles = big5_us.groupby('age group')[traits].median()\n\nage_profiles = big5_us.groupby('age group')[traits].median()\n\nage_profiles.columns = ['Extraversion',\n                        'Agreeableness',\n                        'Conscientiousness',\n                        'Neuroticism',\n                        'Openness']\n\nage_profiles\n\n\n\n\n\n\n\n\nExtraversion\nAgreeableness\nConscientiousness\nNeuroticism\nOpenness\n\n\nage group\n\n\n\n\n\n\n\n\n\nUnder 18\n49.0\n42.0\n37.0\n44.0\n52.0\n\n\n18–24\n49.0\n54.0\n52.0\n50.0\n52.0\n\n\n25–34\n53.0\n59.0\n57.0\n54.0\n58.0\n\n\n35–49\n53.0\n59.0\n67.0\n62.0\n52.0\n\n\n50+\n57.0\n65.0\n67.0\n66.0\n58.0"
  }
]